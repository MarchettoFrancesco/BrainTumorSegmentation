{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e7c3622-7709-4717-b3f8-933ee3f9cc05",
   "metadata": {},
   "source": [
    "We trained the final versions with the best parameters we observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c9babc-04f9-4947-8fa7-06fde008a5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODICE UNET CHE VA BENE\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from skimage import io\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import segmentation_models_pytorch as smp\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import wandb  # For logging\n",
    "from sklearn.metrics import jaccard_score  # For IoU in evaluation\n",
    "\n",
    "# WandB setup (replace with your key or use env var; init once)\n",
    "#wandb.login(key='')  # Or export WANDB_API_KEY\n",
    "wandb.init(project='Zuliani1_Marchetto2', name='efficientnet-b2_U-Net_MRI_Segmentation')  # Customize name\n",
    "\n",
    "# 1. Data Preparation\n",
    "data_dir = '/home/stud/fmarchetto/SegmentationTests/Data/kaggle_3m/'  \n",
    "image_paths = []\n",
    "mask_paths = []\n",
    "\n",
    "for case_folder in os.listdir(data_dir):\n",
    "    case_path = os.path.join(data_dir, case_folder)\n",
    "    if not os.path.isdir(case_path):\n",
    "        continue\n",
    "    for file in os.listdir(case_path):\n",
    "        if file.endswith('.tif') and not file.endswith('_mask.tif'):\n",
    "            image_paths.append(os.path.join(case_path, file))\n",
    "            mask_file = file.replace('.tif', '_mask.tif')\n",
    "            mask_paths.append(os.path.join(case_path, mask_file))\n",
    "\n",
    "print(f\"Total Images: {len(image_paths)}\")\n",
    "print(f\"Total Masks: {len(mask_paths)}\")\n",
    "\n",
    "# Create DataFrame\n",
    "data = pd.DataFrame({\n",
    "    \"image_path\": image_paths,\n",
    "    \"mask_path\": mask_paths\n",
    "})\n",
    "\n",
    "# Add tumor status\n",
    "tumor_status = []\n",
    "for mask_path in tqdm(data[\"mask_path\"], desc=\"Checking masks\"):\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if mask is None or np.max(mask) == 0:\n",
    "        tumor_status.append(\"Non-Tumor\")\n",
    "    else:\n",
    "        tumor_status.append(\"Tumor\")\n",
    "\n",
    "data[\"status\"] = tumor_status\n",
    "print(data[\"status\"].value_counts())\n",
    "\n",
    "# Plot tumor vs non-tumor count\n",
    "counts = data[\"status\"].value_counts()\n",
    "plt.figure(figsize=(6,4))\n",
    "bars = plt.bar(counts.index, counts.values, color=[\"red\", \"gray\"])\n",
    "plt.title(\"Tumor vs Non-Tumor Image Count\", fontsize=14)\n",
    "plt.xlabel(\"Category\")\n",
    "plt.ylabel(\"Number of Images\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.bar_label(bars, padding=3)\n",
    "plt.show()\n",
    "\n",
    "# Preprocessing function (resize to 128x128, normalize)\n",
    "IMG_SIZE = 128\n",
    "def process_image(image_path, mask_path, img_size=IMG_SIZE):\n",
    "    image = cv2.imread(image_path)\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    image = cv2.resize(image, (img_size, img_size))\n",
    "    mask = cv2.resize(mask, (img_size, img_size))\n",
    "    \n",
    "    image = image / 255.0  # Normalize\n",
    "    mask = mask / 255.0\n",
    "    mask = np.where(mask > 0.5, 1, 0)  # Binary\n",
    "    \n",
    "    return image.astype(np.float32), mask.astype(np.float32).reshape(img_size, img_size, 1)\n",
    "\n",
    "# Process all data\n",
    "images = []\n",
    "masks = []\n",
    "for img_path, msk_path in zip(data[\"image_path\"], data[\"mask_path\"]):\n",
    "    img, msk = process_image(img_path, msk_path)\n",
    "    images.append(img)\n",
    "    masks.append(msk)\n",
    "\n",
    "images = np.array(images)\n",
    "masks = np.array(masks)\n",
    "\n",
    "print(\"Images shape:\", images.shape)\n",
    "print(\"Masks shape:\", masks.shape)\n",
    "\n",
    "# Split data (80/10/10)\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, masks, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Val:\", X_val.shape, y_val.shape)\n",
    "print(\"Test:\", X_test.shape, y_test.shape)\n",
    "\n",
    "# Visualize samples (adapted from Kaggle)\n",
    "def visualize_samples(images, masks, n_samples=4):\n",
    "    tumor_indices = [i for i in range(len(masks)) if np.any(masks[i] > 0)]\n",
    "    non_tumor_indices = [i for i in range(len(masks)) if not np.any(masks[i] > 0)]\n",
    "\n",
    "    tumor_samples = np.random.choice(tumor_indices, min(n_samples, len(tumor_indices)), replace=False)\n",
    "    non_tumor_samples = np.random.choice(non_tumor_indices, min(n_samples, len(non_tumor_indices)), replace=False)\n",
    "\n",
    "    fig, axs = plt.subplots(2, n_samples, figsize=(12, 8))\n",
    "    for col, idx in enumerate(tumor_samples):\n",
    "        axs[0, col].imshow(images[idx])\n",
    "        axs[0, col].imshow(masks[idx].squeeze(), cmap=\"Reds\", alpha=0.4)\n",
    "        axs[0, col].title.set_text(\"Tumor\")\n",
    "        axs[0, col].axis(\"off\")\n",
    "\n",
    "    for col, idx in enumerate(non_tumor_samples):\n",
    "        axs[1, col].imshow(images[idx])\n",
    "        axs[1, col].imshow(masks[idx].squeeze(), cmap=\"Reds\", alpha=0.3)\n",
    "        axs[1, col].title.set_text(\"No Tumor\")\n",
    "        axs[1, col].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_samples(X_test, y_test, n_samples=5)\n",
    "\n",
    "# Augmentation (using Albumentations, PyTorch equivalent of ImageDataGenerator)\n",
    "data_gen_args = A.Compose([\n",
    "    A.Rotate(limit=10, p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=0, p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# DataLoader for PyTorch\n",
    "class MRI_Dataset(Dataset):\n",
    "    def __init__(self, images, masks, transform=None):\n",
    "        self.images = images\n",
    "        self.masks = masks\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        mask = self.masks[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=img, mask=mask)\n",
    "            img = augmented['image']  # tensor [C, H, W]\n",
    "            mask = augmented['mask']  # tensor [H, W] or [C, H, W] for grayscale\n",
    "        else:\n",
    "            # FIXED: Manual conversion to tensor if no transform (numpy H W C -> tensor C H W)\n",
    "            img = torch.from_numpy(img.transpose(2, 0, 1)).float()  # [C, H, W]\n",
    "            mask = torch.from_numpy(mask.transpose(2, 0, 1)).float()  # [1, H, W]\n",
    "        \n",
    "        print(f\"Mask shape after processing: {mask.shape}\")  # Debug (remove after testing)\n",
    "        \n",
    "        return img, mask\n",
    "\n",
    "# Create loaders\n",
    "batch_size = 16\n",
    "train_dataset = MRI_Dataset(X_train, y_train, transform=data_gen_args)\n",
    "val_dataset = MRI_Dataset(X_val, y_val)  # No transform for val\n",
    "test_dataset = MRI_Dataset(X_test, y_test)  # No transform for test\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 3. Model Definition (U-Net with ResNet34 backbone from smp, similar to Kaggle's custom U-Net)\n",
    "#model = smp.Unet(\n",
    "#    encoder_name=\"resnet34\",  # Pretrained backbone\n",
    "#    encoder_weights=\"imagenet\",  # Use pretrained weights\n",
    "#    in_channels=3,  # RGB images\n",
    "#    classes=1,  # Binary mask\n",
    "#    activation=None  # For binary output\n",
    "#)\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"efficientnet-b2\",  # Change to this for a different model\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=3,\n",
    "    classes=1,\n",
    "    activation=None\n",
    ")\n",
    "# Move to GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Loss (BCE + Dice, like Kaggle)\n",
    "class BCE_Dice_Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bce = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        \n",
    "        if target.shape[1] != 1:  # If target is [batch, H, W, 1], permute to [batch, 1, H, W]\n",
    "            target = target.permute(0, 3, 1, 2)\n",
    "        elif target.ndim == 3:  # If [batch, H, W], unsqueeze to [batch, 1, H, W]\n",
    "            target = target.unsqueeze(1)\n",
    "        \n",
    "        bce = self.bce(pred, target)\n",
    "        pred_sig = torch.sigmoid(pred)\n",
    "        intersection = (pred_sig * target).sum(dim=(2,3))\n",
    "        dice = (2 * intersection + 1e-6) / (pred_sig.sum(dim=(2,3)) + target.sum(dim=(2,3)) + 1e-6)\n",
    "        dice_loss = 1 - dice.mean()\n",
    "        return bce + dice_loss\n",
    "\n",
    "# Metrics (Dice and IoU, like Kaggle)\n",
    "def dice_coef(y_true, y_pred, threshold=0.5, smooth=1):\n",
    "    y_true = y_true.view(-1)\n",
    "    y_pred = torch.sigmoid(y_pred)   \n",
    "    y_pred = (y_pred > threshold).float().view(-1)\n",
    "    intersection = (y_true * y_pred).sum()\n",
    "    return (2. * intersection + smooth) / (y_true.sum() + y_pred.sum() + smooth)\n",
    "\n",
    "def iou_coef(y_true, y_pred, threshold=0.5, smooth=1):\n",
    "    y_true = y_true.view(-1)\n",
    "    y_pred = torch.sigmoid(y_pred)   \n",
    "    y_pred = (y_pred > threshold).float().view(-1)\n",
    "    intersection = (y_true * y_pred).sum()\n",
    "    union = y_true.sum() + y_pred.sum() - intersection\n",
    "    return (intersection + smooth) / (union + smooth)\n",
    "\n",
    "# ADDED: Accuracy metric (pixel-wise)\n",
    "def accuracy(y_true, y_pred, threshold=0.5):\n",
    "    y_true = y_true.view(-1)\n",
    "    y_pred = torch.sigmoid(y_pred)  # Convert logits to probabilities\n",
    "    y_pred = (y_pred > threshold).float().view(-1)\n",
    "    correct = (y_pred == y_true).float()\n",
    "    return correct.mean()\n",
    "\n",
    "# Compile (optimizer, loss)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = BCE_Dice_Loss()\n",
    "\n",
    "# Callbacks (PyTorch equivalents)\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=8, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = np.inf\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "early_stop = EarlyStopping(patience=8)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, min_lr=1e-7)\n",
    "\n",
    "checkpoint_path = \"best_unetEfficentNet2_model.pth\"  # Save best model\n",
    "\n",
    "# Training Loop with WandB Logging\n",
    "epochs = 50\n",
    "best_val_loss = np.inf\n",
    "history = {'train_loss': [], 'val_loss': [], 'val_dice': [], 'val_iou': [], 'train_acc': [], 'val_acc': []}  # ADDED train/val acc to history\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_acc = 0  # ADDED\n",
    "    for img, mask in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} - Train\"):\n",
    "        img, mask = img.to(device), mask.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(img)\n",
    "        loss = loss_fn(pred, mask)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        train_acc += accuracy(mask, pred).item()  \n",
    "        \n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc /= len(train_loader) \n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_dice = 0\n",
    "    val_iou = 0\n",
    "    val_acc = 0  \n",
    "    with torch.no_grad():\n",
    "        for img, mask in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} - Val\"):\n",
    "            img, mask = img.to(device), mask.to(device)\n",
    "            pred = model(img)\n",
    "            val_loss += loss_fn(pred, mask).item()\n",
    "            val_dice += dice_coef(mask, pred).item()\n",
    "            val_iou += iou_coef(mask, pred).item()\n",
    "            val_acc += accuracy(mask, pred).item()  \n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    val_dice /= len(val_loader)\n",
    "    val_iou /= len(val_loader)\n",
    "    val_acc /= len(val_loader)  \n",
    "    \n",
    "    # Log to WandB \n",
    "    wandb.log({\n",
    "        'epoch': epoch + 1,\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'train_acc': train_acc,   \n",
    "        'val_acc': val_acc,       \n",
    "        'val_dice': val_dice,\n",
    "        'val_iou': val_iou\n",
    "    })\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}, Val Dice = {val_dice:.4f}, Val IoU = {val_iou:.4f}, Train Acc = {train_acc:.4f}, Val Acc = {val_acc:.4f}\")\n",
    "    \n",
    "    # Scheduler and early stopping\n",
    "    scheduler.step(val_loss)\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        wandb.save(checkpoint_path)  # Log artifact to WandB\n",
    "        print(\"Saved best model!\")\n",
    "    \n",
    "    if early_stop(val_loss):\n",
    "        print(\"Early stopping!\")\n",
    "        break\n",
    "\n",
    "# Finish WandB run\n",
    "wandb.finish()\n",
    "\n",
    "# Load best model for evaluation\n",
    "model.load_state_dict(torch.load(checkpoint_path))\n",
    "model.eval()\n",
    "\n",
    "# Test Evaluation \n",
    "test_loss = 0\n",
    "test_dice = 0\n",
    "test_iou = 0\n",
    "test_acc = 0  # ADDED\n",
    "with torch.no_grad():\n",
    "    for img, mask in tqdm(test_loader, desc=\"Test\"):\n",
    "        img, mask = img.to(device), mask.to(device)\n",
    "        pred = model(img)\n",
    "        test_loss += loss_fn(pred, mask).item()\n",
    "        test_dice += dice_coef(mask, pred).item()\n",
    "        test_iou += iou_coef(mask, pred).item()\n",
    "        test_acc += accuracy(mask, pred).item()  \n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "test_dice /= len(test_loader)\n",
    "test_iou /= len(test_loader)\n",
    "test_acc /= len(test_loader)  \n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Dice Coefficient: {test_dice:.4f}\")\n",
    "print(f\"Test IoU Coefficient: {test_iou:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")  \n",
    "\n",
    "# Visualization (adapted from Kaggle)\n",
    "def visualize_predictions(model, images, masks, num_samples=5):\n",
    "    model.eval()\n",
    "    indices = np.random.choice(len(images), num_samples)\n",
    "    fig, axs = plt.subplots(num_samples, 3, figsize=(12, num_samples * 3))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for row, idx in enumerate(indices):\n",
    "            img = torch.from_numpy(images[idx]).permute(2, 0, 1).unsqueeze(0).to(device)  # [1, 3, H, W]\n",
    "            true_mask = masks[idx].squeeze()\n",
    "            pred = model(img)\n",
    "            pred_mask = (pred.squeeze().cpu().numpy() > 0.5).astype(np.uint8)\n",
    "            \n",
    "            axs[row, 0].imshow(images[idx])\n",
    "            axs[row, 0].set_title(\"MRI\")\n",
    "            axs[row, 0].axis(\"off\")\n",
    "            \n",
    "            axs[row, 1].imshow(true_mask, cmap='gray')\n",
    "            axs[row, 1].set_title(\"True Mask\")\n",
    "            axs[row, 1].axis(\"off\")\n",
    "            \n",
    "            axs[row, 2].imshow(pred_mask, cmap='gray')\n",
    "            axs[row, 2].set_title(\"Predicted Mask\")\n",
    "            axs[row, 2].axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_predictions(model, X_test, y_test, num_samples=6)\n",
    "\n",
    "# Optional\n",
    "def tumor_detection_accuracy(model, images, masks, threshold=0.5):\n",
    "    correct = 0\n",
    "    total = len(images)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(total):\n",
    "            img = torch.from_numpy(images[i]).permute(2, 0, 1).unsqueeze(0).to(device)\n",
    "            pred = model(img)\n",
    "            pred_has_tumor = np.any(pred.cpu().numpy() > threshold)\n",
    "            true_has_tumor = np.any(masks[i] > 0)\n",
    "            if pred_has_tumor == true_has_tumor:\n",
    "                correct += 1\n",
    "    return correct / total * 100\n",
    "\n",
    "detection_acc = tumor_detection_accuracy(model, X_test, y_test)\n",
    "print(f\"Tumor Detection Accuracy: {detection_acc:.2f}%\")\n",
    "\n",
    "# Plot Training History\n",
    "ef = pd.DataFrame(history)\n",
    "ef[['train_loss', 'val_loss']].plot(title=\"Loss\")\n",
    "ef[['val_dice', 'val_iou', 'val_acc']].plot(title=\"Metrics\")  \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
